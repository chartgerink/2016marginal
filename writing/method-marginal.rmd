---
output: word_document
bibliography: ../bibliography/bibliography-marginal.bib
csl: ../bibliography/apa.csl
figures: yes
---
```{r global_options, include=FALSE}
knitr::opts_chunk$set(fig.width=6, fig.height=4, echo=FALSE, warning=FALSE, message=FALSE)
```
```{r r_objects}
marginal <- readRDS("./marginal_rmarkdown_objects.RData")
```

##Method
All code and data for this project is available at osf.io/28gxz (preserved at [XXXX]). Introduction, method section, data, bibliography (up until method section) as well as code for data cleaning, test sample creation, analysis, and creation of in-text values/tables (up until method section) are preregistered at osf.io/XXXX. Data were available before pre-registration, but we used a hold-out sample. 
###Data
We reused downloaded articles from @10.3390/data1030014, consisting of 74,489 articles published between 1985 and 2016 in 74 APA journals (`r signif(100*(74/93), digits = 2)`% of currently existing APA journals). As @10.3390/data1030014 only downloaded articles in HTML format, the time span for each journal depends on the year articles became available in HTML format. We limited ourselves to data from journals belonging to the APA, since the APA divides their journals into topics [@APAjournals]. We use these topics to represent nine psychological subfields: "_Basic / Experimental Psychology_" (experimental psychology), "_Clinical Psychology_" (clinical psychology), "_Developmental Psychology_" (developmental psychology), "_Educational Psychology, School Psychology & Training_" (educational psychology), "_Forensic Psychology_" (forensic psychology), "_Health Psychology & Medicine_" (health psychology), "_Industrial/Organizational Psychology & Management_" (organizational psychology), "_Neuroscience & Cognition_" (cognitive psychology), and "_Social Psychology & Social Processes_" (social psychology). The topic "_Core of Psychology_" [@APAjournals] consists of journals that publish on general or interdisciplinary psychology, and we therefore do not consider it a psychological subfield and exclude it as such from the current paper. Four journals and `r marginal$difarticles` articles were unique to this category, but are included in the overall analysis. See appendix A for a detailed breakdown of journals (not) included in the sample, and their division into topics and subfields. 

We converted downloaded HTML articles into raw text, using the python tool 'html2text (https://pypi.python.org/pypi/html2text). We extracted the following information from each article using regular expressions: DOI (when available), raw text of the _p_-values (_e.g._ "$p=.048$"), sign of the _p_-value comparison ('>','<' or '='), the _p_-value itself, and the 200 characters preceding the reported _p_-value, and the 200 characters immediately following. These data we collated into one large dataset containing `r marginal$entries.original` entries.

###Data Preparation
We excluded a small number of entries from the extracted data due to misreporting or extraction failure (Figure 1). We removed entries lacking DOI (and journal name/year; n = `r marginal$nodoi`, `r marginal$nodoipercent`% of total), and all rows where the _p_-values were not numerical (_e.g._ equal to "."; n = `r marginal$badp`, `r marginal$badppercent`% of total). This does not include _p_-values that were misreported as too high (_e.g._ $p = 1.2$ instead of $p = .12$) or as possible _p_-values (_e.g._ $p = .99$ instead of $p = .099$). However, according to @10.3758/s13428-015-0664-2 [p. 1212], misreporting occurs for only about .97% of nonsignificant _p_-values (defined as $p > .05$). 

In continuation, we added subfield categories to each row. In preparation for this we retrieved missing metadata (years and journal name) for `r marginal$mis.meta` (`r marginal$mis.metapercent`% of total) entries using the r-package 'rcrossref' [@rcrossref] and standardized journal names for all entries, with older journal names updated to their current APA-names (2017, see Appendix A). We then added dummies for the subfield categories to all rows. 

Finally, we excluded _p_-values outside of the range of .05 - .1 and created a test sample. Limiting the dataset to _p_-values $.05 < p \leq.1%$, resulted in a final sample consisting of `r marginal$entries.final` (`r marginal$entries.finalpercent`% of total) _p_-values. From the finished dataset, we drew a stratified random sample (by journal) of 6% for testing and pre-registering analytic code. For our analyses we used the full final dataset (including the test sample data).

```{r flowchart, fig.cap="_Figure 1._ Flowchart illustrating the process generating the test sample and the final dataset.", echo = FALSE, fig.align='center'}
knitr::include_graphics("../figures/flowchart_marginal.png", auto_pdf = TRUE)
```

Table 1 summarizes the data per subfield. Following the APA's categorization, a journal may belong to and its results be counted towards multiple subfields (see also Appendix A). To determine whether a result was reported as marginally significant, we searched the 200 characters preceding and the 200 characters succeeding a given _p_-value for the patterns "margin\*" and "approach\*" using regular expressions, and considered the _p_-value to be reported as marginally significant if either of those patterns was found. Only searching the 200 characters preceding the _p_-value decreased the percentage of results considered marginally significant by `r marginal$marg.diff.overall`% overall and with `r marginal$marg.diff.max`% for the subfield with the largest decrease (social psychology).

```{r table_1}
library(knitr)
kable(marginal$table1, caption = "Table 1. Specification for different psychological subfields of the number of APA journals scanned for _p_-values, the number of articles with extracted data, the number of _p_-values extracted (and per article), the number of _p_-values between .05 and .1 (and per article), and the percentage of _p_-values between .05 and .1 that were reported as marginally significant. All values after removal of non-numerical _p_-values and _p_-values in articles without DOI, journal name and year (n = 1,124; 0.14% of total _p_-values).", align = "l", col.names = c("Field", "Journals", "Articles", "_p_-values (per article)", ".05 < p <= .1 (per article)", "Marg. Sig. In %"))
```

Table 2 compares our data with that provided by @10.1177/0956797616645672 (available at https://osf.io/92xqk/) with respect to the two APA-journals (DP and JPSP) that their article and ours have in common. @10.1177/0956797616645672 were only concerned with the binary option of whether an article contained a 'marginally significant' result or not, and consequently each row in their dataset represent a different article. As such, their data does not include the total number  of _p_-values, nor the number of _p_-values between .05 and .1. Moreover, their percentage of 'marginally significant' results is the proportion of articles containing at least one result reported as marginally significant, whereas in the current paper that percentage is the proportion of _p_-values between .05 and .1 reported as marginally significant. 

```{r table_2}
library(knitr)
kable(marginal$table2, caption = "Table 2. Comparison between the data of @10.1177/0956797616645672 and the current paper with respect to the journals 'Journal of Personality and Social Psychology' (JPSP) and 'Developmental Psychology' (DP). Presented are time span of downloaded articles, the number of articles examined, the number of _p_-values extracted (and per article), the number of _p_-values between .05 and .1 (and per article), and the percentage of _p_-values  that were reported as marginally significant. The dataset of @10.1177/0956797616645672 does not include information on the total number of _p_-values nor the number of _p_-values between .05 and .1, resulting in NA-values. Values for the current paper are after removal of non-numerical _p_-values and _p_-values in articles without DOI, journal name and year (0.14% of overall _p_-values)" , align = "l", col.names = c("Journal", "Time Span", "Articles", "_p_-values (per article)", ".05 < p <= .1 (per article)", "Marg. Sig. In %"))
```


###Analyses

Due to using a non-random sample (only APA-articles available in HTML format at the time of download), we present only descriptive statistics. Consequently, we did not perform a power analysis. To aid interpretation we estimate simple linear regressions using least squares estimation, and report _b_-values and the coefficients of determination. Our sole dependent variable is the percentage of_p_-values ($.05 < p \leq.1%$) reported as marginally significant, and our sole independent variable is the year (range 1985 - 2016 including endpoints) of publication of the articles from which _p_-values were extracted. For each year, we calculated the arithmetic mean of 'marginally significant' results. In addition, we report arithmetic means across the years of percentage _p_-values ($.05 < p \leq.1%$) reported as marginally significant for each grouping of data (see table 1 and 2)

We present our results in two steps. First, we present results for the journals JPSP and DP. Here we also highlight the years (1990, 2000, 2010) which our dataset shares with that of @10.1177/0956797616645672 for the two journals. Secondly, we present the results for all APA-journals taken together, and nine different psychological subfields (see table 1). We ran all analyses using R version 3.4.1 [@Rref].


##References
