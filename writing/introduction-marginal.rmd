---
title: "Introduction FYP"
output: word_document
bibliography: ../bibliography/bibliography-marginal.bib
csl: ../bibliography/apa.csl
---

@10.1177/0956797616645672 examined the incidence of articles reporting results as 'marginally' significant in psychology. The researchers looked at the frequency with which articles substantively report at least one result as marginally significant or approaching significance, in a snapshot of articles from the journals 'Cognitive Psychology', 'Developmental Psychology', and the 'Journal of Personality and Social Psychology' (JPSP) for the years 1970, 1980, 1990, 2000, and 2010. In total 1,535 articles were extracted, meant to "represent three major subfields of psychology: cognitive, developmental, and social" (p. 1037) over time. @10.1177/0956797616645672 drew two conclusions: 1) the proportion of articles reporting results as marginally significant (or variations thereof) has risen considerably in all three journals over the time period 1970 to 2010; 2) articles published in JPSP (representing social psychology) were more likely to interpret results as marginally significant than articles in 'Cognitive Psychology' or 'Developmental Psychology' (representing their respective fields). 

Unfortunately, @10.1177/0956797616645672's two conclusions regarding the prevalence of 'marginally significant' results in psychology may be incorrect due to a confounding factor. Their outcome variable was the proportion of papers reporting one or more results as marginally significant. However, if an article contains more _p_-values, there are also more possibilities for marginally significant results and thus that something is reported as marginally significant. Problematically, @10.1177/0956797616645672's outcome measure does not take into account the fact that the number of reported _p_-values per journal article has increased over the years, nor that articles in JPSP on average contain more _p_-values than those in (at least) 'Developmental Psychology'[@10.3758/s13428-015-0664-2]. Consequently, even if a _p_-value is just as likely to be reported as marginally significant over the years, newer articles will be more likely to contain at least one 'marginally significant' result than older articles. In fact, even if the truth was that there had been a decrease in 'marginally significant' results, @10.1177/0956797616645672 could find an increase. Similarly, if articles in a certain journal on average contain more _p_-values, more papers in that journal will report at least one marginally significant result. Articles in JPSP contain almost twice as many _p_-values as those in 'Developmental Psychology' [@10.3758/s13428-015-0664-2], though data is not available on 'Cognitive Psychology'. Thus, using as the outcome variable the proportion of papers reporting at least one result as marginally significant provides little to no information on researchers' usage of the concept of marginal significance, neither over time nor across journals.

In the current paper we examine @10.1177/0956797616645672's two claims that 1) 'marginally significant' results have become more prevalent over time in the three subfields of cognitive, social, and developmental psychology and 2) that results are reported as marginally significant more frequently in social psychology than in cognitive or developmental psychology. We adapted our dependent variable to take into account the varying number of _p_-values between different years and different journals. As such, we look at the proportion of _p_-values reported as marginally significant across years and journals. More specifically, since a large portion of _p_-values are unlikely to be interpreted as marginally significant by researchers [i.e., $p\leq.05%$ and $p > .1$; @10.3758/s13428-015-0664-2; @10.1177/0956797616645672] we look at the proportion of _p_-values between .05 and .1 reported as marginally significant across years and subfields. Following @10.1177/0956797616645672, if the strings "marginal" or "approach" appear in conjunction with a reported _p_-value, we considered it to be reported as marginally significant.

Whole parts of the scientific literature can be effectively examined using automated methods. Based on such automated methods several recent publications have successfully used extracted statistics to examine the scientific literature [e.g., @10.7717/peerj.1142; @10.3758/s13428-015-0664-2; @10.1080/19312458.2015.1096333]. One of the most common automated methods is using so called regular expressions that search through the provided (article) text for pre-defined strings of text, the results of which are then saved to a data file for analysis. That this method only searches for pre-defined strings is a limitation that is greater the more complex the format of the data to be extracted. Fortunately, when solely extracting _p_-values only 3 things need be identified in the text: the 'p', the comparison sign, and the value itself [see @10.1093/biostatistics/kxt007, and discussions in the same issue for an extensive treatment on the extraction of _p_-values]. The advantage of automated methods when examining the scientific literature is that they permit collecting large samples of data; for example, @10.3758/s13428-015-0664-2, despite using a R-package ('statcheck') that only extracts complete APA-formatted test results (t-, F-values etc), collected 258,105 _p_-values from 30,717 articles published between 1985 and 2013. 

Using automated extraction of _p_-values, we replicate and extend @10.1177/0956797616645672. @10.1177/0956797616645672 examined the incidence of 'marginally significant' results in three psychological subfields: Cognitive, developmental and social psychology. However, they did so using only one journal to represent each subfield, and with data from only five years for each journal. Using automated extraction, we collect data from all articles published between 1985 and 2016 in journals pertaining to the American Psychological Association (APA). This permits us to examine @10.1177/0956797616645672's claims with data from 32 consecutive years per subfield, and with a number of journals making up each subfield, thus decreasing the risk of sampling bias and increasing precision of trend estimates. Moreover, it also allows us to examine the prevalence of 'marginally significant' results in APA-journals overall, and in six psychological subfields beyond those explored by @10.1177/0956797616645672: Clinical psychology, educational psychology, experimental psychology, forensic psychology, health psychology, and organizational psychology.



##References
