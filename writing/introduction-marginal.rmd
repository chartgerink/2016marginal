---
title: "Introduction FYP"
output: html_document
bibliography: ../bibliography/bibliography-marginal.bib
csl: ../bibliography/apa.csl
---

@10.1177/0956797616645672 examined the incidence of articles reporting results as 'marginally' significant in psychology. The researchers looked at the frequency with which articles report at least one result as 'marginally significant' or 'approaching significance', in a snapshot of articles from the journals 'Cognitive Psychology', 'Developmental Psychology', and the 'Journal of Personality and Social Psychology' (JPSP) for the years 1970, 1980, 1990, 2000, and 2010. In total 1,535 articles were extracted, meant to "represent three major subfields of psychology: cognitive, developmental, and social" (p. 1037) over time. @10.1177/0956797616645672 drew two conclusions: First, that the proportion of articles reporting results as marginally significant (or variations thereof) has risen considerably in all three journals over the time period 1970 to 2010. Second, that articles published in JPSP (representing social psychology) were more likely to interpret results as marginally significant than articles in 'Cognitive Psychology' or 'Developmental Psychology' (representing their respective fields). 

Unfortunately, @10.1177/0956797616645672's two conclusions regarding the prevalence of 'marginally significant' results in psychology may well be false due to ignoring an important confounder. Their outcome variable was the proportion of papers reporting one or more results as marginally significant. However, if an article contains more p-values, then there are also more possibilities for marginally significant results. Problematically, @10.1177/0956797616645672's outcome measure does not take into account the fact that the number of reported p-values per journal article has increased over the years, nor that articles in JPSP on average contain more p-values than those in (at least) 'Developmental Psychology'[@10.3758/s13428-015-0664-2]. Consequently, even if a p-value is just as likely to be reported as marginally significant over the years, newer articles will be more likely to contain at least one 'marginally significant' result than older articles. This may be the case even if the likelihood of 'marginally significant' results is decreasing somewhat. Similarly, if articles in a certain journal on average contain more p-values, more papers in that journal will report at least one marginally significant result. Articles in JPSP contain almost twice as many p-values as those in 'Developmental Psychology' [@10.3758/s13428-015-0664-2], though data is not available on 'Cognitive Psychology'. Thus, using as an outcome variable the proportion of papers reporting at least one result as marginally significant provides little to no information on researchers' usage of the concept of marginal significance, neither over time nor across journals.

In the current paper we re-examine @10.1177/0956797616645672's two claims that i) 'marginally significant' results have become more prevalent over time in the three subfields of cognitive, social, and developmental psychology, and ii) that results are reported as marginally significant more frequently in social psychology than in cognitive or developmental psychology. We adapted our dependent variable to take into account the varying number of p-values between different years and different journals. As such, we look at the _proportion_ of p-values reported as marginally significant across years and journals. More specifically, since a large portion of p-values are unlikely to be interpreted as marginally significant by researchers (_i.e._ $p <= .5$ and $p > .1$; @10.3758/s13428-015-0664-2; @10.1177/0956797616645672) we look at the proportion of p-values between .05 and .1 reported as marginally significant across years and subfields. Following @10.1177/0956797616645672, if the strings "marginal" or "approach" appear in conjunction with a reported p-value, we considered it to be reported as marginally significant.

The scientific literature can be effectively examined using automated methods. Based on such automated methods several recent publications have successfully used extracted statistics to examine the scientific literature [_e.g._ @10.3758/s13428-015-0664-2; @10.1080/19312458.2015.1096333]. These methods typically search through the provided text (article) for pre-defined strings of text, and the results are then saved to a data file for analysis. The primary advantage of such automated methods is that they permit collecting large samples of data; for example, @10.3758/s13428-015-0664-2 collected 258,105 p-values from 30,717 articles published between 1985 and 2013. 

Using automated extraction of p-values, we extend the scope of the present article beyond replicating @10.1177/0956797616645672. We do this by looking at all articles published between 1985 and 2016 in journals pertaining to the American Psychological Association (APA). This allows us to examine the prevalence of 'marginally significant' results in APA-journals overall, and seven psychological subfields beyond those explored by @10.1177/0956797616645672: Clinical psychology, 'core of psychology', educational psychology, experimental psychology, forensic psychology, health psychology, and organizational psychology. Moreover, due to the large sample made possible by automated extraction of data, we are able to include more years and journals in each subfield than was possible for @10.1177/0956797616645672, decreasing the risk of sampling bias and increasing precision of trend estimates.


##References

