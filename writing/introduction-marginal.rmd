---
title: "Introduction FYP"
output: word_document
bibliography: ../bibliography/bibliography-marginal.bib
csl: ../bibliography/apa.csl
---

@10.1177/0956797616645672 examined the incidence of articles reporting results as 'marginally' significant in psychology. The researchers looked at the frequency with which articles report at least one result as 'marginally significant' or 'approaching significance', in a snapshot of articles from the journals 'Cognitive Psychology', 'Developmental Psychology', and the 'Journal of Personality and Social Psychology' (JPSP) for the years 1970, 1980, 1990, 2000, and 2010. In total 1,535 articles were extracted, meant to "represent three major subfields of psychology: cognitive, developmental, and social" (p. 1037) over time. @10.1177/0956797616645672 drew two conclusions: First, that the proportion of articles reporting results as marginally significant (or variations thereof) has risen considerably in all three journals over the time period 1970 to 2010. Second, that articles published in JPSP (representing social psychology) were more likely to interpret results as marginally significant than articles in 'Cognitive Psychology' or 'Developmental Psychology' (representing their respective fields). 

Unfortunately, @10.1177/0956797616645672's two conclusions regarding the prevalence of 'marginally significant' results in psychology may well be false due to ignoring an important confounder. Their outcome variable was the proportion of papers reporting one or more results as marginally significant. However, if an article contains more p-values, then there are also more possibilities for marginally significant results. Problematically, @10.1177/0956797616645672's outcome measure does not take into account the fact that the number of reported p-values per journal article has increased over the years, nor that articles in JPSP on average contain more p-values than those in (at least) 'Developmental Psychology'[@10.3758/s13428-015-0664-2]. Consequently, even if a p-value is just as likely to be reported as marginally significant over the years, newer articles will be more likely to contain at least one 'marginally significant' result than older articles. This may be the case even if the likelihood of 'marginally significant' results is decreasing somewhat. Similarly, if articles in a certain journal on average contain more p-values, more papers in that journal will report at least one marginally significant result. Articles in JPSP contain almost twice as many p-values as those in 'Developmental Psychology' [@10.3758/s13428-015-0664-2], though data is not available on 'Cognitive Psychology'. Thus, using as an outcome variable the proportion of papers reporting at least one result as marginally significant provides little to no information on researchers' usage of the concept of marginal significance, neither over time nor across journals.

In the current paper we re-examine @10.1177/0956797616645672's two claims that i) 'marginally significant' results have become more prevalent over time in the three subfields of cognitive, social, and developmental psychology, and ii) that results are reported as marginally significant more frequently in social psychology than in cognitive or developmental psychology. We adapted our dependent variable to take into account the varying number of p-values between different years and different journals. As such, we look at the _proportion_ of p-values reported as marginally significant across years and journals. More specifically, since a large portion of p-values are unlikely to be interpreted as marginally significant by researchers (_i.e._ $p <= .5$ and $p > .1$; @10.3758/s13428-015-0664-2; @10.1177/0956797616645672) we look at the proportion of p-values between .05 and .1 reported as marginally significant across years and subfields. Following @10.1177/0956797616645672, if the strings "marginal" or "approach" appear in conjunction with a reported p-value, we considered it to be reported as marginally significant.

The scientific literature can be effectively examined using automated methods. Based on such automated methods several recent publications have successfully used extracted statistics to examine the scientific literature [_e.g._ @10.7717/peerj.1142; @10.3758/s13428-015-0664-2; @10.1080/19312458.2015.1096333]. These automated methods typically search through the provided text (article) for pre-defined strings of text, and the results are then saved to a data file for analysis. That these methods only search for pre-defined strings is a limitation that is greater the more complex the format of the data to be extracted. For example, the R-package 'statcheck' [@10.3758/s13428-015-0664-2] recalculates p-values and therefore requires the full statistics (t-, F-values etc) to be correctly reported in APA-format, creating many possible points of extraction failure. On the other hand, when solely extracting p-values, only 3 things must exist: the 'p', the comparison sign, and the value itself [see @10.1093/biostatistics/kxt007, and discussions in the same issue for an extensive treatment on the extraction of p-values, albeit from abstracts]. The advantage of automated methods when examining the scientific literature is that they permit collecting large samples of data; for example, @10.3758/s13428-015-0664-2, despite the limitations of 'statcheck', collected 258,105 p-values from 30,717 articles published between 1985 and 2013. 

Using automated extraction of p-values, we extend the scope of the present article beyond replicating @10.1177/0956797616645672. @10.1177/0956797616645672 examined the incidence of 'marginally significant' results in three psychological subfields: Cognitive, developmental and social psychology. However, they did so using only one journal to represent each subfield, and with data from only five years for each journal. Using automated extraction, we collect data from all articles published between 1985 and 2016 in journals pertaining to the American Psychological Association (APA). This permits us to re-examine @10.1177/0956797616645672's claims with data from 31 consecutive years per subfield, and with a number of journals making up each subfield, thus decreasing the risk of sampling bias and increasing precision of trend estimates. Moreover, it also allows us to examine the prevalence of 'marginally significant' results in APA-journals overall, and in six psychological subfields beyond those explored by @10.1177/0956797616645672: Clinical psychology, educational psychology, experimental psychology, forensic psychology, health psychology, and organizational psychology.



##References
